{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec94c57f-a5d7-49b9-9506-4db545d7d79f",
   "metadata": {},
   "source": [
    "#### Import library and setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414024fe-9173-4621-94f7-026199cb717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show wider options\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1391e08-35e8-42e4-85b7-55bd648f06a3",
   "metadata": {},
   "source": [
    "#### Clean data, standardize Vietnamese (remove accents, stop words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda430b-ea46-4cc1-9d5c-983f4d775533",
   "metadata": {},
   "source": [
    "##### Text cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e049bf31-d4bf-4162-9d59-8c81e873e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()  # convert to lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)  # remove link\n",
    "    text = re.sub(r\"[^a-zA-Z0-9àáạảãâầấậẩẫăằắặẳẵèéẹẻẽêềếệểễ\"\n",
    "                  r\"ìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữỳýỵỷỹđ\\s]\", '', text)  # remove special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406894cf-d3cd-45b8-a6ab-c8d8ab8552fb",
   "metadata": {},
   "source": [
    "1. **Chuyển thành chữ thường:** giúp thống nhất dữ liệu (`\"Tốt\"` → `\"tốt\"`).  \n",
    "2. **Xóa liên kết (URL):** loại bỏ các đường dẫn web (`https://...`).  \n",
    "3. **Xóa ký tự đặc biệt:** chỉ giữ lại chữ, số và ký tự tiếng Việt.  \n",
    "4. **Xóa khoảng trắng thừa:** gom nhiều khoảng trắng thành một, xóa đầu/cuối."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9037f-1d0d-4a45-ba06-7d2ea5ea924b",
   "metadata": {},
   "source": [
    "##### Vietnamese accent removal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879a29fa-d43a-4cad-ad02-6de51d7f29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vietnamese_accents(text):\n",
    "    # Split letters and accents into separate parts (e.g. 'ệ' -> 'e' and '̣')\n",
    "    nfkd_form = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    # Keep the non-accent characters, then concatenate them\n",
    "    return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e5df4-b4a7-4091-a88b-6832e70555bd",
   "metadata": {},
   "source": [
    "1. **Chuẩn hóa ký tự:** tách phần chữ và phần dấu (`'ệ' → 'e' + '̣'`).\n",
    "2. **Loại bỏ dấu:** giữ lại ký tự gốc, bỏ phần dấu (`'đẹp quá' → 'dep qua'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919be1c-ce90-4dd2-99e3-3ab51c4086cd",
   "metadata": {},
   "source": [
    "##### Remove stopwords function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934790d4-d2a9-4eca-8240-7054536a8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    words = text.split()  # Split text into list words.\n",
    "    \n",
    "    filtered = [w for w in words if w not in stopwords]  # Filter words that are not stopwords.\n",
    "    \n",
    "    return \" \".join(filtered)  # Concatenate filtered to string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86160d61-acd0-4d8e-a681-e5c1679d24e1",
   "metadata": {},
   "source": [
    "1. **Tách câu thành danh sách từ:** (`\"tôi thích uống trà\"` → `[\"tôi\", \"thích\", \"uống\", \"trà\"]`)\n",
    "2. **Lọc bỏ từ dừng:** giữ lại những từ không nằm trong danh sách stopwords.\n",
    "3. **Ghép lại thành chuỗi:** (`[\"thích\", \"uống\", \"trà\"]` → `\"thích uống trà\"`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd705b-5a59-4f13-bec0-b59bbf25a17a",
   "metadata": {},
   "source": [
    "##### Download the list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef9489f3-0f0d-41cb-aeb1-88fc3b59bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(open(\"D:/Projects/Sentiment_Analysis/data/external/vietnamese-stopwords.txt\", \"r\", encoding=\"utf-8\").read().splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3176d8bc-c411-4532-8672-7fde2c856b6f",
   "metadata": {},
   "source": [
    "#### Read and Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34b4bd8-b4d7-47a6-9152-d58a646f8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each episode\n",
    "train_df = pd.read_csv(\"D:/Projects/Sentiment_Analysis/data/interim/train.csv\")\n",
    "test_df  = pd.read_csv(\"D:/Projects/Sentiment_Analysis/data/interim/test.csv\")\n",
    "dev_df   = pd.read_csv(\"D:/Projects/Sentiment_Analysis/data/interim/dev.csv\")\n",
    "\n",
    "# Apply the same handler function to all three\n",
    "for df in [train_df, test_df, dev_df]:\n",
    "    df[\"sentence\"] = df[\"sentence\"].apply(clean_text)\n",
    "    df[\"sentence\"] = df[\"sentence\"].apply(remove_vietnamese_accents)\n",
    "    df[\"sentence\"] = df[\"sentence\"].apply(lambda x: remove_stopwords(x, stopwords))\n",
    "\n",
    "# Save\n",
    "train_df.to_csv(\"D:/Projects/Sentiment_Analysis/data/processed/train_clean.csv\", index=False)\n",
    "test_df.to_csv(\"D:/Projects/Sentiment_Analysis/data/processed/test_clean.csv\", index=False)\n",
    "dev_df.to_csv(\"D:/Projects/Sentiment_Analysis/data/processed/dev_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
