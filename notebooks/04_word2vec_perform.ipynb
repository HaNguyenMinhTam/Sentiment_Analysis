{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b4d3e5-0d73-43bb-9d9e-835d0d49a856",
   "metadata": {},
   "source": [
    "#### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "240df093-db8f-416e-9bf9-e9c150d8b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9f7dc-2892-4014-8e6e-7140ad68b209",
   "metadata": {},
   "source": [
    "#### Read and Show shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b3cda91-4a19-4230-91d8-6a9808130f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (11426, 3)\n",
      "Dev: (3166, 3)\n",
      "Test: (3166, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slide giao trinh day du</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhiet tinh giang day gan gui voi sinh vien</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>di hoc day du full diem chuyen can</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chua ap dung cong thong va cac thiet bi ho tro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thay giang bai co nhieu bai tap vi du tren lop</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment  topic\n",
       "0                            slide giao trinh day du          2      1\n",
       "1         nhiet tinh giang day gan gui voi sinh vien          2      0\n",
       "2                 di hoc day du full diem chuyen can          0      1\n",
       "3  chua ap dung cong thong va cac thiet bi ho tro...          0      0\n",
       "4     thay giang bai co nhieu bai tap vi du tren lop          2      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"D:/Projects/Sentiment_Analysis/data/processed/train_clean.csv\")\n",
    "dev_df   = pd.read_csv(\"D:/Projects/Sentiment_Analysis/data/processed/dev_clean.csv\")\n",
    "test_df  = pd.read_csv(\"D:/Projects/Sentiment_Analysis/data/processed/test_clean.csv\")\n",
    "\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Dev:\", dev_df.shape)\n",
    "print(\"Test:\", test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35dd8b-977b-40aa-a376-6bfbb5d9cc11",
   "metadata": {},
   "source": [
    "#### Preparing Word2Vec training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f0c659-8e02-4730-aa83-a8f7e970ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the data type is string\n",
    "train_df['sentence'] = train_df['sentence'].astype(str)\n",
    "dev_df['sentence'] = dev_df['sentence'].astype(str)\n",
    "test_df['sentence'] = test_df['sentence'].astype(str)\n",
    "\n",
    "# Then separate from\n",
    "sentences = [text.split() for text in train_df['sentence']]\n",
    "dev_sentences = [text.split() for text in dev_df['sentence']]\n",
    "test_sentences = [text.split() for text in test_df['sentence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a119d9d-6ee1-42e7-bf0d-872f47369f00",
   "metadata": {},
   "source": [
    "#### Fit the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f54e904-a75f-4909-8c84-4763b51eee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,   # training data\n",
    "    vector_size=100,        # number of dimensions of the vector (usually 100–300)\n",
    "    window=5,               # context size (5 words around)\n",
    "    min_count=2,            # ignore words that appear < 2 times\n",
    "    workers=4,              # number of CPU threads\n",
    "    sg=1                    # skip-gram (1) or CBOW (0)\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "w2v_model.save(\"D:/Projects/Sentiment_Analysis/models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa0cd9-1922-4cb4-be08-e15fe3a8a864",
   "metadata": {},
   "source": [
    "#### Convert each sentence to a mean vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1be16cc-1435-4897-af5e-7b2364672ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the average vector of a sentence\n",
    "def get_sentence_vector(tokens, model):\n",
    "    valid_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(valid_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)  # if the sentence is empty or has no valid word\n",
    "    return np.mean(valid_vectors, axis=0)\n",
    "\n",
    "# Create a vector matrix for all data\n",
    "X_train_w2v = np.array([get_sentence_vector(tokens, w2v_model) for tokens in sentences])\n",
    "X_dev_w2v = np.array([get_sentence_vector(tokens, w2v_model) for tokens in dev_sentences])\n",
    "X_test_w2v = np.array([get_sentence_vector(tokens, w2v_model) for tokens in test_sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05165152-e88e-4dce-92db-2e9050644b8e",
   "metadata": {},
   "source": [
    "#### Save embedding to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9695b103-c447-45fc-beac-f141467d4271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ D:\\Projects\\Sentiment_Analysis\\models\\Word2Vec/word2vec_features.pkl\n",
      "X_train: (11426, 100)\n"
     ]
    }
   ],
   "source": [
    "# Lưu vectorizer\n",
    "joblib.dump(train_df[\"sentiment\"].values, \"D:/Projects/Sentiment_Analysis/models/Word2Vec/y_train.pkl\")\n",
    "joblib.dump(dev_df[\"sentiment\"].values, \"D:/Projects/Sentiment_Analysis/models/Word2Vec/y_dev.pkl\")\n",
    "joblib.dump(test_df[\"sentiment\"].values, \"D:/Projects/Sentiment_Analysis/models/Word2Vec/y_test.pkl\")\n",
    "\n",
    "# Lưu ma trận TF-IDF dạng nén (nếu muốn)\n",
    "np.savez_compressed(\"D:/Projects/Sentiment_Analysis/data/features/Word2Vec/X_train_w2v.npz\", X_train_w2v)\n",
    "np.savez_compressed(\"D:/Projects/Sentiment_Analysis/data/features/Word2Vec/X_dev_w2v.npz\", X_dev_w2v)\n",
    "np.savez_compressed(\"D:/Projects/Sentiment_Analysis/data/features/Word2Vec/X_test_w2v.npz\", X_test_w2v)\n",
    "\n",
    "print(\"✅ D:\\Projects\\Sentiment_Analysis\\models\\Word2Vec/word2vec_features.pkl\")\n",
    "print(\"X_train:\", X_train_w2v.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sentiment_env)",
   "language": "python",
   "name": "sentiment_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
